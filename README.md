# ğŸ¤– Query Agent


An intelligent multi-modal query agent powered by LangGraph and DSPy that seamlessly handles both RAG (Retrieval-Augmented Generation) and SQL queries from documents and databases, supports questions in both Arabic and English, and provides an interactive GUI built with Streamlit for easy use.

![LangGraph Workflow](./graph.png)

## ğŸ“‹ Overview

Query Agent intelligently routes user questions to the appropriate data source (files or database) using a 7-node LangGraph workflow. It supports both Arabic and English questions, leverages DSPy for optimized natural language to SQL conversionâ€”significantly reducing token usage while improving accuracyâ€”and offers an interactive Streamlit GUI for a user-friendly experience.


### Key Features

- **ğŸ”€ Intelligent Query Routing**: Automatically determines whether to use RAG or SQL based on query analysis
- **ğŸ“„ Multi-Format Document Support**: Process and query various file formats
- **ğŸ—„ï¸ SQL Database Integration**: Natural language to SQL conversion with semantic example selection
- **ğŸ¯ DSPy Optimization**: Uses 50 training examples in arabic and english with semantic embeddings to select the 2 most relevant examples for accurate SQL generation
- **ğŸ–¥ï¸ Interactive GUI**: Built with Streamlit for easy interaction
- **ğŸ“Š Visual Workflow**: Clear graph representation of the decision-making process

## ğŸ—ï¸ Architecture

The agent consists of 7 interconnected nodes in a LangGraph workflow:


1. **Router Node**: Determines the optimal path (RAG or SQL or Hybried)
2. **Planer Node**: analyzes the user request and generates a structured, step-by-step plan for how the graph should handle the task
3. **RAG Node**: Retrieves and processes information from documents
4. **SQL Node**: Converts natural language to SQL using DSPy optimization
5. **Execution Node**: Executes queries against the database
6. **repair loop Node**:  attempts to fix invalid SQL queries and retries up to three times before failing.
7. **Synthesis Node**: Combines results and generates final responses


### NL2SQL Optimization with DSPy

The system uses an innovative approach to improve SQL generation:
- Pre-computed embeddings for 50 SQL examples
- Semantic similarity search to find the 2 most relevant examples
- Dynamic schema injection with context-aware examples
- Significant token reduction and accuracy improvement

## ğŸš€ Getting Started

### Prerequisites

- Python 3.11+
- pip or conda package manager
- Access to a SQL database (PostgreSQL, MySQL, SQLite, etc.)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/aahmedehab0/Query-Agent.git
cd Query-Agent
git checkout main
```

2. **Create a virtual environment**
```bash
# Using venv
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Or using conda
conda create -n query-agent python=3.11
conda activate query-agent
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**



```bash
$ cp .env.example .env
```

5. **Prepare your data**

- Place your documents in the `assets/files/` folder
- Place your database in the `assets/database/` folder
- Ensure your database is accessible and properly configured


## ğŸ’» Usage

### Running the Streamlit GUI

```bash
streamlit run app.py
```

The interface will open in your browser at `http://localhost:8501`



## ğŸ“‚ Project Structure

```
â”œâ”€â”€ License
â”œâ”€â”€ README.md
â”œâ”€â”€ app.py
â””â”€â”€ src
    â”œâ”€â”€ .env.example
    â”œâ”€â”€ .gitignore
    â”œâ”€â”€ agent
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ dspy_modules.py
    â”‚   â””â”€â”€ graph_nodes.py
    â”œâ”€â”€ assets
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ database
    â”‚   â”‚   â”œâ”€â”€ Chinook_Sqlite.sqlite
    â”‚   â”‚   â””â”€â”€ __init__.py
    â”‚   â”œâ”€â”€ examples
    â”‚   â”‚   â”œâ”€â”€ arabic_questions.jsonl
    â”‚   â”‚   â””â”€â”€ english_questions.jsonl
    â”‚   â”œâ”€â”€ files
    â”‚   â”‚   â”œâ”€â”€ Chinook_Database_Overview.pdf
    â”‚   â”‚   â””â”€â”€ __init__.py
    â”œâ”€â”€ controllers
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ base_controller.py
    â”‚   â””â”€â”€ process_controller.py
    â”œâ”€â”€ helpers
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ config.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ models
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ enums
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ lang_enums.py
    â”‚   â”‚   â””â”€â”€ processing_enums.py
    â”‚   â””â”€â”€ schemas
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â””â”€â”€ agent_schema.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ stores
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â””â”€â”€ semantic_retriever.py
    â””â”€â”€ tools
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ prompt_generator.py
        â””â”€â”€ sql_helper.py

```

## ğŸ”§ Configuration

### Database Setup

Supported databases:
- PostgreSQL
- MySQL
- SQLite
- SQL Server


## ğŸ“Š Performance

- **Token Reduction**: ~40% fewer tokens compared to standard NL2SQL approaches
- **Accuracy**: Improved SQL generation accuracy using semantic example selection
- **Response Time**: Average response time < 3 seconds for most queries


## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- Built with [LangGraph](https://github.com/langchain-ai/langgraph)
- Optimized using [DSPy](https://github.com/stanfordnlp/dspy)
- UI powered by [Streamlit](https://streamlit.io/)
